import yaml
import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import models
import os
import time
import math
import shutil
from models import affine_net
from losses import losses
from datasets.dataset import FundusImageDataset
from torch.utils.data import DataLoader
from tqdm import tqdm

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
# è°ƒç”¨yamlæ–‡ä»¶
def load_config(config_path):
    with open(config_path, 'r') as f :
        config = yaml.safe_load(f)
    return config

def record_experiment_info(base_dir: str) -> str:
    """
    
    :param base_dir: çˆ¶è·¯å¾„ç›®å½•ï¼Œ
    :type base_dir: str
    :return: æ–°åˆ›å»ºçš„å®éªŒç›®å½•å®Œæ•´è·¯å¾„
    :rtype: str
    """
    os.makedirs(base_dir, exist_ok=True)

    # æ”¶é›†æ‰€æœ‰åˆæ³•çš„ experiment_N ç›®å½•å¹¶æå–ç¼–å·
    exp_ids = []
    for d in os.listdir(base_dir):
        if d.startswith("experiment_") and d[11:].isdigit():
            exp_ids.append(int(d[11:]))

    next_id = max(exp_ids) + 1 if exp_ids else 1
    exp_dir = os.path.join(base_dir, f"experiment_{next_id}")
    
    os.makedirs(exp_dir, exist_ok=False)  # ç¡®ä¿ä¸è¦†ç›–å·²æœ‰ç›®å½•
    return exp_dir


# å®šä¹‰ä¸»è®­ç»ƒè„šæœ¬
def main():
# åŠ è½½é…ç½®
    config = load_config('configs/config.yaml')
    training_cfg = config['training']

    # ä¸€æ¬¡æ€§è§£åŒ…å¸¸ç”¨å‚æ•°
    epochs = training_cfg['epochs']
    lr = training_cfg['learning_rate']
    batch_size = training_cfg['batch_size']
    weight_decay = training_cfg['weight_decay']
    affine_weight_path = training_cfg['affine_weight_path']
    base_channels = training_cfg['base_channels']
    input_mode = training_cfg['input_mode']
    input_size = training_cfg['input_size']
    dataset_path = training_cfg['dataset_path']
    mean = training_cfg['mean']
    std = training_cfg['std']
    jl_thresh_mode = training_cfg['jl_thresh_mode']

    # å®šä¹‰è®­ç»ƒé›†ã€éªŒè¯é›†ã€æµ‹è¯•é›†ï¼Œå¹¶åŠ è½½åˆ°åŠ è½½å™¨ä¸­
    train_dataset = FundusImageDataset(
        root_dir = os.path.join(dataset_path, 'train'),
        mean = mean, std = std,
        standard_size = tuple(input_size)
    )
    val_dataset = FundusImageDataset(
        root_dir = os.path.join(dataset_path, 'val'),
        mean = mean, std = std,
        standard_size = tuple(input_size)
    )
    test_dataset = FundusImageDataset(
        root_dir = os.path.join(dataset_path, 'test'),
        mean = mean, std = std,
        standard_size = tuple(input_size)
    )

    train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True)
    val_loader = DataLoader(val_dataset, batch_size = batch_size, shuffle = False)
    test_loader = DataLoader(test_dataset, batch_size = batch_size, shuffle = False)
    
    # è®°å½•å®éªŒå‚æ•°ï¼Œä¿å­˜å®éªŒç»“æœè·¯å¾„
    current_exp_dir = record_experiment_info(affine_weight_path)
    print(f"ğŸ””Starting new experiment:{current_exp_dir}")
    # ä¿å­˜æœ¬æ¬¡å®éªŒçš„é…ç½®æ—¥å¿—
    log_config = {
        'experiment_id': int(os.path.basename(current_exp_dir).split('_')[-1]),
        'epochs': epochs,
        'learning_rate': lr,
        'batch_size': batch_size,
        'weight_decay': weight_decay,
        'base_channels': base_channels,
        'input_mode': input_mode,
        'input_size': input_size,
        'dataset_path': dataset_path,
        'mean': mean,
        'std': std,
        'timestamp': time.strftime("%Y-%m-%d %H:%M:%S")
    }
    log_path = os.path.join(current_exp_dir, 'train_config.yaml')
    with open(log_path, 'w', encoding='utf-8') as f:
        yaml.dump(log_config, f, default_flow_style=False, indent=4, allow_unicode=True)
    print(f"ğŸ“ Saved config to {log_path}")


    # å®šä¹‰æ–°çš„ç½‘ç»œç»“æ„
    model = affine_net.AffineNet(
        base_channels=base_channels,
        input_mode = input_mode,
        input_size = input_size
    )
    model.to(device)
    print(model)
    # å®šä¹‰ä¼˜åŒ–å™¨
    optimizer = optim.Adam(model.parameters(), lr=lr)
    criterion = losses.DesignLoss(
        mean = mean, std=std,
        jl_thresh_mode = jl_thresh_mode
        ).mi_clipmse
    best_val_loss = float('inf')

    for epoch in range(epochs):
        print(f"\nEpoch {epoch+1}/{epochs}")
        print("-" * 30)

        # ----------------å¼€å§‹è®­ç»ƒ------------------
        model.train()
        train_loss = 0.0
        train_bar = tqdm(train_loader, desc=f"Train Epoch {epoch+1}", leave=True)
        for batch_idx, (src, tgt) in enumerate(train_bar):
            src, tgt = src.to(device), tgt.to(device)

            optimizer.zero_grad()
            warped_src, affine_param = model(src, tgt)
            loss_train = criterion(tgt, warped_src)
            loss_train.backward()
            optimizer.step()

            train_loss += loss_train.item()
            train_bar.set_postfix({'loss':f"{loss_train.item():.6f}"})
        avg_train_loss = train_loss / len(train_loader)
        print(f"Train Loss:{avg_train_loss:.6f}")

        # ----------------å¼€å§‹éªŒè¯-----------------
        model.eval()
        val_loss = 0.0
        val_bar = tqdm(val_loader, desc=f"Val Epoch {epoch+1}", leave=False)
        with torch.no_grad():
            for src, tgt in val_bar:
                src, tgt = src.to(device), tgt.to(device)
                warped_src, affine_param = model(src, tgt)
                loss_val = criterion(tgt, warped_src)
                val_loss += loss_val.item()
                val_bar.set_postfix({'val_loss': f"{loss_val.item():.6f}"})
        avg_val_loss = val_loss / len(val_loader)
        print(f"Val Loss:{avg_val_loss:.6f}")

        # ----------------ä¿å­˜æœ€ä½³æ¨¡å‹-----------------
        if avg_val_loss < best_val_loss:
            best_val_loss = avg_val_loss
            save_path = os.path.join(current_exp_dir, f"best_model_epoch{epoch+1}.pth")
            torch.save({
                'epoch': epoch,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'val_loss': avg_val_loss,
            }, save_path)
            print(f"Saved best model to {save_path}")
    print("\n Training finished")


if __name__ == "__main__" :
    main()